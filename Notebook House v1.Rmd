---
title: "R Notebook for the Housepricing Comp"
output: html_notebook
---

```{r admin, include = FALSE}
##clean out the space
rm(list=ls())
options(scipen=999)

##What do we need
library(tidyr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(cowplot) # plot different ggplots next to each other
#install.packages("DataExplorer")
library(DataExplorer)
library(corrplot)
library(pscl) # For Pseudo R squareds on GLMS

#Where will we work
getwd()
setwd("C:/Users/helen/Documents/Kaggle/HousePrice")

```

The Data explorer package is great for a first stab at unknown data. First things first;

-   The dependent variable - the thing we want to predict - is continuous --\> regression problem
    -   GLM: Gamma with Log, Inverse or Identity link
    -   Regression Tree
    -   Random Forrest Reg Tree
-   Not normally distributed --\> important to match the algo to the distribution transformation
    -   Gool ol' OLS with a transformation?
-   Loads of missing data to remedy
    -   Which means we should add the test and train sets together - to save effort when scoring & validating

```{r EDA}

train<-read.csv("train.csv")

train['Type']<-'train_set'

test<-read.csv("test.csv")
test['SalePrice'] <- NA
test['Type']<-'test_set'

data<-rbind(train,test)

#create_report(train)
#create_report(data)
plot_intro(data)
plot_missing(data)
```

Start by filling in the missing data and running some correlation plots to understand the multicollinearity;

-   By completing the NA values we drop from 5.8% missing observations to 0.33%

-   The remaining two significantly missing values are for

    -   LotFrontage and

    -   Garage built

-   The latter's missing value shows there is no Garage on the premises while the LotFrontage might just show that the property is not on a municipal street. However this may be an incorrect assumption so lets start by plugging the values with 0 for LotFrontage but perhaps check different values for future submissions, and the Garage built to 3000 to represent the future.

```{r CleanupandFill}
#Fill in the NA's where they represent 'None Present' with 'Non' 

data_f<-data %>%
  replace_na(list(Alley = "Non", BsmtQual = "Non", BsmtExposure = "Non",
                  BsmtCond= "Non", BsmtFinType1="Non", BsmtFinType2="Non",
                  FireplaceQu = "Non", GarageType = "Non",GarageFinish = "Non",
                  GarageQual="Non", GarageCond="Non", 
                  PoolQC="Non", Fence = "None", GarageQual="Non", 
                  GarageCond = "Non", PoolQC = "Non", MiscFeature = "Non"))

data_f<-data_f %>%
  replace_na(list(LotFrontage = 0, 
                  GarageYrBlt = 3000))

#create_report(data_f)
plot_intro(data_f)
plot_missing(data_f)


data_fg<-data_f
data_fg$MSSubClass<-as.factor(data_fg$MSSubClass)
data_fg$HouseStyle<-as.factor(data_fg$HouseStyle)

#subset(data_fg,SaleType=="Other")
b<-ggplot(data=data_fg, aes(x=MSSubClass, y=SalePrice))+
  geom_boxplot()

bb<-ggplot(data=data_fg, aes(x=HouseStyle, y=SalePrice))+
  geom_boxplot()

g<-ggplot(data=data_fg, aes(x=MSSubClass) )+
  geom_bar() 

gg<-ggplot(data=data_fg, aes(x=HouseStyle) )+
  geom_bar() 

plot_grid(g, b, ncol = 2, nrow = 1)

plot_grid(gg, bb, ncol = 2, nrow = 1)

ggplot(data=data_fg, aes(x=MSSubClass, fill = HouseStyle, y = 1 ) )+
  geom_bar(position="fill", stat="identity") 

data_fg$Era<-case_when(data_fg$MSSubClass == 20 ~ 'Newer',
                   data_fg$MSSubClass == 60 ~ 'Newer',
                   data_fg$MSSubClass == 120 ~ 'Newer',  
                   data_fg$MSSubClass == 160 ~ 'Newer',
                     data_fg$MSSubClass == 30 ~ 'Older',
                     data_fg$MSSubClass == 70 ~ 'Older',
                   TRUE ~ 'NoAgeDifferentiation'  )

g1 <- ggplot(data=data_fg, aes(x=Era) )+
  geom_bar() 

g2 <-ggplot(data=data_fg, aes(x=Era, y=SalePrice))+
  geom_boxplot()

plot_grid(g1, g2, ncol = 2, nrow = 1)

```

```{r REGROUPING}
##Regroup poorly represented factor levels
data_fg<-data_f
#Resulting factor changes
data_fg$Era<-case_when(data_fg$MSSubClass == 20 ~ 'Newer',
                   data_fg$MSSubClass == 60 ~ 'Newer',
                   data_fg$MSSubClass == 120 ~ 'Newer',  
                   data_fg$MSSubClass == 160 ~ 'Newer',
                     data_fg$MSSubClass == 30 ~ 'Older',
                     data_fg$MSSubClass == 70 ~ 'Older',
                   TRUE ~ 'NoAgeDifferentiation'  )

data_fg$MSZoning<-as.factor(case_when(data_fg$MSZoning ==  "C (all)"  ~ "C (all)",
                            data_fg$MSZoning =="FV" ~ "FV",
                            data_fg$MSZoning == "RL" ~ "RL/RP",
                            data_fg$MSZoning == "RP" ~ "RL/RP",
                            TRUE ~'Other'))
data_fg$MSZoning <-fct_reorder(data_fg$MSZoning, data_fg$SalePrice)

data_fg$SaleType<-as.factor(case_when(data_fg$SaleType == 'COD' ~ 'COD',
          data_fg$SaleType == 'Con' ~ 'GCon', #Contract grouped
          data_fg$SaleType == 'ConLw' ~ 'GCon',
          data_fg$SaleType == 'ConLI' ~ 'GCon',
          data_fg$SaleType == 'ConLD' ~ 'GCon',
          data_fg$SaleType == 'New' ~ 'New',
          data_fg$SaleType == 'WD' ~ 'GWD',
          data_fg$SaleType == 'CWD' ~ 'GWD',
          data_fg$SaleType == 'VWD' ~ 'GWD',
          TRUE ~'Other'
          ))
data_fg$SaleType<-(fct_reorder(data_fg$SaleType, data_fg$SalePrice))
```

remaining missing rows for the training data set can't be explained. Let's drop these rows from the training set to run our first few models. The new plots show we have a complete data set

```{r FillingInMissing}
subset(mcd, is.na(MSZoning) == TRUE )

#training set
data_f_t<-subset(data_f, Type=="train_set")            
data_f_t<-subset(data_f_t, is.na(MasVnrType) == FALSE )
data_f_t<-subset(data_f_t, is.na(Electrical) == FALSE )

plot_intro(data_f_t)
plot_missing(data_f_t)  
#create_report(data_f_t)


```

The correlation heatmap from the ExploratoryData package's report is too dense to read properly. For a parameterised model multicollinearity is not good at all.

```{r MULTICOLLINEARITY}
factorNames <- c('MSSubClass', 'MSZoning')
data_f <- data_f %>%
  mutate(across(factorNames, as.factor))

str(data_f)

data_f<-
mcd<-data_f[,c(2:3,81)]
plot_correlation(mcd)
plot_correlation(mcd$MSZoning)

b1<-ggplot(data=mcd, aes(x=MSSubClass, y=SalePrice))+
  geom_boxplot()

b2<-ggplot(data=mcd, aes(x=MSZoning, y=SalePrice))+
  geom_boxplot()

g1<-ggplot(data=mcd, aes(x=MSSubClass) )+
  geom_bar() 

g2<-ggplot(data=mcd, aes(x=MSZoning) )+
  geom_bar() 

plot_grid(b1, g1, ncol = 2, nrow = 1)
plot_grid(b2, g2, ncol = 2, nrow = 1)

subset(mcd, is.na(MSZoning) == TRUE )
```

```{r DependentDistributionExploration}

ggplot(data_f_t, aes(x=SalePrice))+
  geom_density(aes(x=SalePrice, y=..density..))

data_f_t$logPrice<-log(data_f_t$SalePrice)

ggplot(data_f_t)+
  geom_density(aes(x=logPrice, y=..density..))


```

The natural log transform does seem to make the dependent variable more symmetrical. Lets explore the three GLMs (Gamma:log, Gamma:inv, gamma:id) with a forward stepwise variable selection to decide which GLM is best

In terms of the model selevction we need a good balance between Mcfadden's pseudo R-square, Nagelkerke's R-square and plain R-square. As expected the McF's R2 is severely penalised due to too many parameters.

```{r}
library(stats)
library(caTools)

str(data_f_t)
#We need to remove the variables we do not want to use in the model;
data_f_t<-data_f_t[,2:81]
set.seed(101) 
sample = sample.split(data_f_t$SalePrice, SplitRatio = .85)
T_Train = subset(data_f_t, sample == TRUE)
T_Val  = subset(data_f_t, sample == FALSE)


glm.M1<-glm(SalePrice~.,
            family=Gamma(link = "log"),
            data    = T_Train)

with(summary(glm.M1), 1 - deviance/null.deviance)
format( pR2(glm.M1), scientific = FALSE)
#summary(glm.M1)

step_gamma_glm<-step(glm.M1)
step_gamma_glm$aic
step_gamma_glm$anova
step_gamma_glm$finalModel

x<-step_gamma_glm$model
yhat<-step_gamma_glm$fitted.values
y<-T_Train$SalePrice
fitted<-as.data.frame(cbind(yhat,y))

finalModel<-glm(formula = SalePrice ~ MSZoning + LotArea + Street + LandContour + 
    Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + 
    Condition2 + BldgType + OverallQual + OverallCond + YearBuilt + 
    YearRemodAdd + RoofMatl + Exterior1st + MasVnrArea + ExterCond + 
    Foundation + BsmtExposure + BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF + 
    Heating + HeatingQC + CentralAir + X1stFlrSF + X2ndFlrSF + 
    LowQualFinSF + BsmtFullBath + FullBath + HalfBath + KitchenAbvGr + 
    KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + GarageYrBlt + 
    GarageCars + GarageArea + GarageQual + GarageCond + WoodDeckSF + 
    EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + PoolQC + 
    Fence + SaleType + SaleCondition, family = Gamma(link = "log"), 
    data = T_Train)
summary(finalModel)



valResult<-predict(finalModel,T_Val)

ggplot(fitted, aes(x=yhat, y=y))+
  geom_jitter()+
  geom_line(aes(x=y, y=y))

mse
```

After that we will do some feature engineering to see if there is an improvement

These are unused codes

```{r}
library(sqldf)
sqldf("Select * from data_f where MasVnrType is null")

c<-sqldf("Select MSZoning, MSSubClass, count(*) from missing
group by MSZoning,MSSubClass
      ")

FV<-sqldf("Select MSZoning, Street, count(*) total, sum(case when LotFrontage is null then 1 else 0 end) count_missing
          from data_f
          group by 1,2")

FV<-sqldf("Select *, sum(count_missing)/sum(total) from FV")
#create_report(data)


VIOLIN PLOT
vp1 <- ggplot(mcd, aes(x=MSSubClass, y=SalePrice)) +
  geom_violin()+
  geom_boxplot(width=0.1)
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
