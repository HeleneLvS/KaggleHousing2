---
title: "R Notebook for the Housepricing Comp"
output: html_notebook
---

```{r setup, include=FALSE}
options(scipen=999) ###No scientific notifications
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message =  FALSE)
```

```{r admin, include = FALSE}
##clean out the space
rm(list=ls())
options(scipen=999)

##What do we need
library(tidyr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(cowplot) # plot different ggplots next to each other
library(DataExplorer) # Best EDA package by far
library(corrplot)
library(pscl) # For Pseudo R squareds on GLMS
library(caTools) #sample
library(pscl)
library(GGally)

#Not used lets remove later
#library(stats)

#Where will we work
#getwd()
setwd("C:/Users/helen/Documents/Kaggle/HousePrice/KaggleHousing")

```

The Data explorer package is great for a first stab at unknown data. First things first;

-   The dependent variable - the thing we want to predict - is continuous --\> regression problem
    -   GLM: Gamma with Log, Inverse or Identity link
    -   Regression Tree
    -   Random Forrest Reg Tree
-   Not normally distributed --\> important to match the algo to the distribution transformation
    -   Gool ol' OLS with a transformation?
-   Loads of missing data to remedy
    -   Which means we should add the test and train sets together - to save effort when scoring & validating

### Raw Combined Data File

```{r EDA}

train<-read.csv("train.csv")

train['Type']<-'train_set'

test<-read.csv("test.csv")
test['SalePrice'] <- NA
test['Type']<-'test_set'

data<-rbind(train,test)

#create_report(train)
#create_report(data)
plot_intro(data)
plot_missing(data)
```

Start by filling in the missing data and running some correlation plots to understand the multicollinearity;

-   By completing the NA values we drop from 5.8% missing observations to 0.33%

-   The remaining two significantly missing values are for

    -   LotFrontage and

    -   Garage built

-   The latter's missing value shows there is no Garage on the premises while the LotFrontage might just show that the property is not on a municipal street. However this may be an incorrect assumption so an alternative is to build a model on LotFrontage as a factor of LotConfig and LotArea. On closer inspection imputing missings with 0's ruins a pretty nice linear correlation between SalePrice and LotFrontage so lets start with the model. There is a separate Impute notebook for details on this. Garage built will be imputed with current year + 1 to represent the future.

```{r CleanupandFilled}
    #Fill in the NA's where they represent 'None Present' with 'None' 
data_f<-data

data_f$BsmtQual<- case_when(
          (is.na(data$BsmtQual) == TRUE & data$TotalBsmtSF >= 0) ~ data$BsmtCond,
          (is.na(data$BsmtQual) == TRUE & data$TotalBsmtSF == 0) ~ "None",
          TRUE~data$BsmtQual
          )
data_f$BsmtCond<- case_when(
          (is.na(data$BsmtCond) == TRUE & data$TotalBsmtSF > 0) ~ "TA",
          (is.na(data$BsmtCond) == TRUE & data$TotalBsmtSF == 0) ~ "None",
          TRUE~data$BsmtCond
          )
data_f$BsmtExposure<-case_when(
          (is.na(data$BsmtExposure) == TRUE & data$TotalBsmtSF > 1000) ~ "Av",
          (is.na(data$BsmtExposure) == TRUE & data$TotalBsmtSF > 0 
                    & data$TotalBsmtSF <= 1000) ~ "No",
          (is.na(data$BsmtExposure) == TRUE & data$TotalBsmtSF == 0) ~ "None",
          TRUE~data$BsmtExposure
          )

data_f$BsmtFinType2<-case_when(
          (is.na(data$BsmtFinType2) == TRUE & data$TotalBsmtSF > 0)~ "ALQ",
          (is.na(data$BsmtFinType2) == TRUE & data$TotalBsmtSF == 0) ~ "None",
          TRUE~data$BsmtFinType2
          )

data_f<-data_f %>%
      replace_na(list(Alley = "None", BsmtQual ="None", BsmtExposure = "None",
                      BsmtCond= "None", BsmtFinType1="None", BsmtFinType2="None",  
                      FireplaceQu = "None", 
                      GarageType = "None",GarageFinish = "None",
                      GarageQual="None", GarageCond="None", 
                      PoolQC="None", Fence = "None", GarageQual="None", 
                      GarageCond = "None",  MiscFeature = "None",
                      MasVnrType = "None"))
data_f<-data_f %>% 
      replace_na(list(GarageCars = 0,
                      GarageArea = 0,
                      BsmtFinSF1 = 0,
                      BsmtFinSF2 = 0,
                      BsmtUnfSF = 0 ,
                      TotalBsmtSF = 0,
                      BsmtFullBath = 0,
                      BsmtHalfBath = 0))

    ## Add this bit for another set: LotFrontage = 0, if the above gives a poor result

##IMPUTE LOTFRONTAGE
## Predict the LotFrontage based on total sqft and Configuration of the lot with m.lf
data_ltz<-subset(data_f, is.na(LotFrontage)==FALSE)
m.lf <- glm(LotFrontage~LotArea+LotConfig, Gamma(link="log"), data = data_ltz)    
remove(data_ltz)
newdata<-data_f
newdata$LotFrontageHat<- predict(m.lf,newdata,type="response")  
iqr<-IQR(newdata$LotFrontage,na.rm=TRUE)
q3<-quantile(newdata$LotFrontage, probs=c(0.75), na.rm=TRUE)

#Cap it
newdata$LotFrontageHat<-case_when(
newdata$LotFrontageHat >= (q3+3*iqr) ~ (q3+3*iqr),                            
      TRUE ~newdata$LotFrontageHat
      )
remove(iqr)
remove(q3)
#Impute it
newdata$LotFrontageF<-case_when(
      is.na(newdata$LotFrontage)==TRUE ~ round(newdata$LotFrontageHat,0),
                      TRUE ~newdata$LotFrontage)
newdata$Cat<-case_when(
      is.na(newdata$LotFrontage)==TRUE ~ "Impute",
                      TRUE ~ "Original")

#Add it back to the dataset we are cleaning
data_f$LotFrontage<-newdata$LotFrontageF
data_f$LotFCat<-newdata$Cat
remove(newdata)

```

```{r REGROUPING}
##Regroup poorly represented factor levels
#Data_fg will be the set that is used for modelling

rm(data_fg)
data_fg<-data_f[,81:82]

#Resulting factor changes
data_fg$Era<-as.factor(case_when(data_f$MSSubClass == 20 ~ 'Newer',
                   data_f$MSSubClass == 60 ~ 'Newer',
                   data_f$MSSubClass == 120 ~ 'Newer',  
                   data_f$MSSubClass == 160 ~ 'Newer',
                     data_f$MSSubClass == 30 ~ 'Older',
                     data_f$MSSubClass == 70 ~ 'Older',
                   TRUE ~ 'NoAgeDifferentiation'  ))

data_fg$MSZoning<-as.factor(case_when(data_f$MSZoning ==  "C (all)"  ~ "C (all)",
                            data_f$MSZoning =="FV" ~ "FV",
                            data_f$MSZoning %in% c("RL","RP") ~ "RL/RP",
                            TRUE ~'Other'))

data_fg$MSZoning <-fct_reorder(data_fg$MSZoning, data_fg$SalePrice)

data_fg<-cbind(data_fg, data_f[,4:7])
data_fg$LotShape<-as.factor(case_when(data_f$LotShape == "Reg" ~ "Reg",
                            TRUE ~ "Irreg"))

data_fg$LandContour<- as.factor(case_when(data_f$LandContour == "HLS" ~ "Other",
                                          data_f$LandContour == "Low" ~ "Other",
                                          TRUE ~ data_f$LandContour))
#Discard Utilities
data_fg$LotConfig <- as.factor(data_f$LotConfig)
data_fg$LandSlope<-as.factor(case_when(data_f$LandSlope == "Gtl" ~ "Gtl",
                            TRUE ~ "Sloped"))
data_fg$Neighborhood <- as.factor(case_when(
  data_f$Neighborhood %in% c("IDOTRR", "BrDale") ~ "IDOTRR_BrDale",
  data_f$Neighborhood %in% c("Blueste", "Sawyer") ~ "Blueste_Sawyer",
  TRUE~data_f$Neighborhood) )
data_fg$Neighborhood <- fct_reorder(data_fg$Neighborhood,data_fg$SalePrice)

data_fg$Condition1 <-substring(data_f$Condition1,1,3)

data_fg$Condition2 <- case_when(
                                 data_f$Condition2 == "Norm" ~ "2Nor",
                                 substring(data_f$Condition2,1,3) == "Pos" ~ "3Pos",
                                 TRUE ~ "1Neg"
                                        )

data_fg$ConComb<-paste(data_fg$Condition1 , data_fg$Condition2, sep = "_") 
data_fg$BldgType<-as.factor(data_f$BldgType)
data_fg$Stories<-as.factor(case_when(data_f$HouseStyle == "1Story" ~ "1.0",
                          data_f$HouseStyle == "1.5Fin" ~ "1.5", 
                          data_f$HouseStyle =="1.5Unf" ~ "1.5",
                          data_f$HouseStyle == "2Story" ~ "2.0",          
                          data_f$HouseStyle == "2.5Fin" ~ "2.5",
                          data_f$HouseStyle == "2.5Unf" ~ "2.5",  
                          TRUE ~ 'Other'  ))
data_fg<-cbind(data_fg, data_f[,18:19])
data_fg$YearBuilt<-data_f$YearBuilt
data_fg$AgeOfHse<-year(now()) - data_f$YearBuilt

data_fg$YearRemodAdd<-case_when(data_f$YearRemodAdd<=data_f$YearBuilt ~ data_f$YearBuilt,
                                TRUE ~ data_f$YearRemodAdd)
data_fg$YrsSRemod<-year(now()) - data_fg$YearRemodAdd
data_fg$RemodYN<- as.factor(case_when(data_fg$YearRemodAdd==data_fg$YearBuilt ~ "Y",
                            TRUE ~ "N"))
data_fg$RoofStyle<- as.factor(data_f$RoofStyle)
data_fg$RoofMatl<-as.factor(case_when(data_f$RoofMatl == "CompShg" ~ "CompShg",
                                      TRUE ~ "Other"))
#unique(data_fg$Exterior1st)
data_fg$Exterior1st<-as.factor(case_when(
data_f$Exterior1st %in% c("AsbShng", "AsphShn", "WdShing") ~"Shingles", 
data_f$Exterior1st %in% c("VinylSd", "MetalSd", "Wd Sdng") ~ "Siding",
data_f$Exterior1st %in% c("CemntBd", "Plywood", "HdBoard", "BrkFace" ) ~ "Board",
data_f$Exterior1st %in% c("BrkComm","CBlock", "ImStucc", "Stucco", 
                         "Other", "PreCast", "Stone") ~ "Other",
                    is.na(data_f$Exterior1st) ~ "Other",
                    TRUE ~ data_f$Exterior1st))

data_fg$Exterior2nd<-as.factor(case_when(
  data_f$Exterior2nd %in% c("AsbShng", "AsphShn", "WdShing", "Wd Shng") ~"Shingles",   data_f$Exterior2nd %in% c("VinylSd", "MetalSd", "Wd Sdng") ~ "Siding",
  data_f$Exterior2nd %in% c("CemntBd", "CmentBd", "Plywood", "HdBoard", "BrkFace" ) ~ "Board",
  data_f$Exterior2nd %in% c("BrkComm", "Brk Cmn", "CBlock", "ImStucc", "Stucco", 
                            "Other", "PreCast", "Stone") ~ "Other",
               is.na(data_f$Exterior2nd) ~ "Other",
               TRUE ~ data_f$Exterior2nd))
data_fg$Ext_Concat<-as.factor(case_when(data_fg$Exterior1st == data_fg$Exterior2nd ~ 
                                          paste("Dbl_",data_fg$Exterior1st),
          TRUE ~ paste(data_fg$Exterior1st,'_Mixed')
          ))

data_fg$CntExtFin<- case_when(data_f$Exterior1st==data_f$Exterior2nd ~ 1 ,
                              TRUE ~ 2)

data_fg$MasVnrType<- as.factor(data_f$MasVnrType)
data_fg$MasVnrArea<- case_when((is.na(data_f$MasVnrArea)==TRUE & 
                                   data_f$MasVnrType =="None") ~ 0,
                               TRUE ~ data_f$MasVnrArea)

data_fg<-cbind(data_fg, data_f[,c("ExterQual","ExterCond")])

data_fg$Foundation<- as.factor(
  case_when(data_f$Foundation %in% c("BrkTil", "CBlock", "PConc") ~ data_f$Foundation,
  TRUE ~ "Other"
  ))
data_fg<-cbind(data_fg,data_f[,c(31:39, 48,49)])
data_fg$BsmtGenInfo<-case_when(data_fg$BsmtQual=="None" ~ "NoBsmt",
                        (data_fg$BsmtQual %in% c("Ex", "Gd", "TA") & 
                          data_fg$BsmtFullBath > 0 &   
                          (data_fg$BsmtFinType1 %in% c("GLQ", "ALQ") |
                               data_fg$BsmtFinType2 %in% c("GLQ","ALQ"))) ~ "RentBsmt",
                        (data_fg$BsmtQual %in% c("Ex", "Gd", "TA") & 
                          data_fg$BsmtCond %in% c("Ex", "Gd", "TA") &
                          (data_fg$BsmtHalfBath+ data_fg$BsmtFullBath) > 0)  ~ "SelfConRecS", 
                        (data_fg$BsmtFinType1 == "Rec" | data_fg$BsmtFinType2 == "Rec") ~ "RecSpace", 
                        (data_fg$BsmtQual %in% c("Ex", "Gd", "TA") & 
                          data_fg$BsmtCond %in% c("Ex", "Gd", "TA") &
                           (data_fg$BsmtFinType1 %in% c("GLQ", "ALQ") |
                               data_fg$BsmtFinType2 %in% c("GLQ","ALQ"))) ~ "RecSpace",  
                        data_fg$BsmtUnfSF == data_fg$TotalBsmtSF ~ "UnfOnly",
                        TRUE ~ "NWSO") #Needs work storage only

data_fg$BsmtGenInfo <-fct_reorder(data_fg$BsmtGenInfo, data_fg$SalePrice)

data_fg$CentralAir<-data_f$CentralAir
data_fg$Heating<-case_when(data_f$Heating == "GasA" ~ "GasA",
                           TRUE ~ "Other")
data_fg$HeatingQC<-as.factor(case_when(data_f$HeatingQC %in% c("Po", "Fa") ~ "PoFa",
                           TRUE ~ data_f$HeatingQC))
data_fg$HeatingQC<-fct_reorder(data_fg$HeatingQC, data_fg$SalePrice)

data_fg$Electrical <- case_when(data_f$Electrical %in% 
                                  c("SBrkr", "FuseA") ~ data_f$Electrical,
                                TRUE~"Other")
data_fg<-cbind(data_fg, data_f[,c(44:47,50:53,55)])
data_fg$KitchenQual<-fct_reorder(as.factor(case_when(data_f$KitchenQual %in% c("Ex", "Gd", "TA") ~data_f$KitchenQual,
                               TRUE ~ "FaOrLess")),data_fg$SalePrice)
data_fg$Functional<-case_when(data_f$Functional =="Typ" ~ "Typ",
                               TRUE ~ "Dedctns")

data_fg<-cbind(data_fg, data_f[,(57:58)])

data_fg$GarageType<-case_when(is.na(data_f$GarageYrBlt)==TRUE ~ "None", 
                              TRUE ~ data_f$GarageType)
data_fg$GarageYrBlt<-case_when(data_f$GarageYrBlt > data_f$YrSold ~ data_f$YrSold,
                           is.na(data_f$GarageYrBlt) == TRUE ~ (year(now())+1),
                           TRUE ~data_f$GarageYrBlt)
data_fg<-cbind(data_fg, data_f[,61:72])
data_fg$PoolQC<-case_when(data_f$PoolQC == "None" ~ "None",
                          TRUE ~ "HasPool")

data_fg<-cbind(data_fg, data_f[,74:78])
data_fg$SaleType<-as.factor(case_when(data_f$SaleType == 'COD' ~ 'COD',
          data_f$SaleType == 'Con' ~ 'GCon', #Contract grouped
          data_f$SaleType == 'ConLw' ~ 'GCon',
          data_f$SaleType == 'ConLI' ~ 'GCon',
          data_f$SaleType == 'ConLD' ~ 'GCon',
          data_f$SaleType == 'New' ~ 'New',
          data_f$SaleType == 'WD' ~ 'GWD',
          data_f$SaleType == 'CWD' ~ 'GWD',
          data_f$SaleType == 'VWD' ~ 'GWD',
          TRUE ~'Other'
          ))
data_fg$SaleType<-(fct_reorder(data_fg$SaleType, data_fg$SalePrice))
data_fg$SaleCondition<-case_when(data_f$SaleCondition %in% c("Normal", "Partial") ~ data_f$SaleCondition , TRUE ~ "Other" )

```

# Post Cleaned, Grouped and Filled data:

Factors with no variance such as Utilities have been dropped

Other insights include the basement variables - can it be used for rental income?
```{r FixFactors}
chr <- sapply(data_fg, is.character)
colS<-names(data_fg[,chr])
data_fg[,colS]<-lapply(data_fg[,colS],factor)

remove(colS)               

#ggplot(data_f_t, aes(x=Neighborhood, y = SalePrice))+ geom_boxplot() +
#theme(axis.text.x = element_text(angle=90))

#ggplot(data_fg, aes(x=Neighborhood))+geom_bar()+
#theme(axis.text.x = element_text(angle=90))


#create_report(data_fg)
plot_missing(data_fg)
```

The new plots show we have a complete data set. (Only the dependent variable for the test set is missing)

The data is split back into the training and test set, to start modelling. The training set is split into a validation set too, to test over-fitting since we are parameterising

The correlation heatmap from the ExploratoryData package's report is too dense to read properly. For a parameterised model multicollinearity is not good at all.We will split the dataset up into readable chunks and assess. 

```{r Resplit}
data_fg$LogY<-log(data_fg$SalePrice)
#test, train & val set
data_f_tst<-subset(data_fg, Type!="train_set")
data_f_tst<-data_f_tst[,-c(2)]
data_f_t<-subset(data_fg, Type=="train_set")  
data_f_t<-data_f_t[,-c(2)]

plot_correlation(data_f_t)

#Just for ease of reading
rm(test)
rm(train)
rm(data_f)
rm(m.lf)
```
###Correlation

To reduce the data set to a more manageable set for the parameterised models, lets remove the variables that have no correlation with log of SalePrice. This is done by first looking at the numerical variables and removing any where the p-value for the correlation between the ln of SalesPrice and the numeric variable is not significant (p >= 0.05) by Spearman correlation

The remaining variables are mostly assessed for near-perfect multicolinearity. 

```{r DropNum}
num<- sapply(data_f_t, is.numeric)
numS<-names(data_f_t[,num])
data_t_n<-data_f_t[,numS] # only numerical training data columns

#Find overall correlations for factor reduction between numericals

ovcor<- as.data.frame(round(cor(data.frame(lapply(data_t_n, as.integer)),
                                use = "pairwise.complete.obs",
                                method = "spearman"),2))
pcor<-as.data.frame(round(ggcorrplot::cor_pmat(ovcor),3))
cordep<-as.tibble(ovcor[,ncol(ovcor)]) # Last column has the log of Y
names(cordep) <- "cor_val"
pcordep<-as.tibble(pcor[,ncol(ovcor)])
names(pcordep) <- "p_val"
cordep<-cbind(cordep, pcordep)
cordep<- cordep %>% mutate(cordep, Index = row_number(), Nom = colnames(data_t_n))
  
RemList<-subset(cordep, p_val >= 0.05 )[,4]

#remove these values from the training sets
data_f_t<-select (data_f_t ,-(RemList))

k=ncol(data_f_t)
# Convert data to numeric
d<-data_f_t[,c(2:k)]
corr<- data.frame(lapply(d, as.integer))
#see correlelogram with numerical factors
ggcorr(corr,
    method = c("pairwise", "spearman"),
    nbreaks = 5,
    hjust = 1,
    size = 2,
    label = TRUE,
    label_size = 2,
    color = "grey50"
    )

rem2<-c("YearBuilt", "YearRemodAdd", #"Condition1", 
        "Condition2", "Exterior1st", 
        "Exterior2nd")
data_f_t<-select (data_f_t ,-(rem2))

set.seed(22) 
sample = sample.split(data_f_t$SalePrice, SplitRatio = .85)

T_Train = subset(data_f_t, sample == TRUE)
T_Val  = subset(data_f_t, sample == FALSE)

rm(ovcor)
rm(pcor)
rm(pcordep)
rm(corr)
rm(d)
rm(data_t_n)
rm(rem2)
rm(num)
rm(numS)
rm(RemSplit)
rm(RemList)
```

The result is that we remove the following variables;

- YearBuilt
- YearRemodAdd
- Exterior1st
- Exterior2nd
- Condition 1
- Condition 2



### To remove here - SOM 

The natural log transform does seem to make the dependent variable more symmetrical. Lets explore the three GLMs (Gamma:log, Gamma:inv, gamma:id) with a forward stepwise variable selection to decide which GLM is best

In terms of the model selection we need a good balance between Mcfadden's pseudo R-square, Nagelkerke's R-square and plain R-square. As expected the McF's R2 is severely penalised due to too many parameters.


```{r DependentDistributionExploration}

ggplot(data_f_t, aes(x=SalePrice))+
  geom_density(aes(x=SalePrice, y=..density..))+
  ggtitle ("SalePrice Distribution")

ggplot(data_f_t)+
  geom_density(aes(x=LogY, y=..density..))+
  ggtitle("Distribution of natural logarithm of SalePrice")

```
### EOM


```{r linseqmod}
#library(ggcorrplot) didn't use this in the end, corr sign is too strict
#install.packages("AutoStepwiseGLM") only works for gaussian identity. No good
#install.packages("leaps")
library(leaps)
#HERE WE DO THE MANUAL LOGY USING LM

lm.K<-lm(LogY~1,data = T_Train[,2:68] )

lm.Full<-lm(LogY~.,data = T_Train[,2:68])

lm.models <- regsubsets(LogY~., 
                     data = T_Train[,2:68],
                     nvmax = 5,
                     method = "forward")


summary(lm.models)

set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(LogY ~., data = T_Train[,2:68],
                    method = "leapSeq", 
                    tuneGrid = data.frame(nvmax = 1:260),
                    trControl = train.control
                    )
step.model$bestTune
step.model$results
step.model$finalModel
coef(step.model$finalModel, 67)

```

```{r}
glm.K<-glm(SalePrice~1, family = Gamma(link="log"), data = T_Train)
summary(glm.K)
glm.All<-glm(SalePrice~., family = Gamma(link="log"), data = T_Train)
summary(glm.All)
glm.All$aic

#ActualPredicted set
ap<-as.data.frame(cbind("Actual" = T_Train$SalePrice, "Predicted_K" = glm.K$fitted.values))


ggplot(ap, aes(x = Actual, y=Predicted_K)) + geom_point()


step_gamma_glm<-step(glm.K,
                     direction = "forward",
                     scope = formula(glm.All),
                     trace=0
                     )
step_gamma_glm$aic
step_gamma_glm$anova
summary(step_gamma_glm)

##Below only works for numerical values???


```

```{r FirstStab}
# Plot the graph

```

```{r}


```

```{r }
glm.M1<-glm(SalePrice~.,
            family=Gamma(link = "log"),
            data    = T_Train[,1:67])

with(summary(glm.M1), 1 - deviance/null.deviance)
format( pR2(glm.M1), scientific = FALSE)
summary(glm.M1)

step_gamma_glm<-step(glm.M1, direction="backwards")

step_gamma_glm$aic
step_gamma_glm$anova
step_gamma_glm$finalModel

x<-step_gamma_glm$model
yhat<-step_gamma_glm$fitted.values
y<-T_Train$SalePrice
fitted<-as.data.frame(cbind(yhat,y))

finalModel<-glm(formula = SalePrice ~ MSZoning + LotArea + Street + LandContour + 
    Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + 
    Condition2 + BldgType + OverallQual + OverallCond + YearBuilt + 
    YearRemodAdd + RoofMatl + Exterior1st + MasVnrArea + ExterCond + 
    Foundation + BsmtExposure + BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF + 
    Heating + HeatingQC + CentralAir + X1stFlrSF + X2ndFlrSF + 
    LowQualFinSF + BsmtFullBath + FullBath + HalfBath + KitchenAbvGr + 
    KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + GarageYrBlt + 
    GarageCars + GarageArea + GarageQual + GarageCond + WoodDeckSF + 
    EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + PoolQC + 
    Fence + SaleType + SaleCondition, family = Gamma(link = "log"), 
    data = T_Train)
summary(finalModel)



valResult<-predict(finalModel,T_Val)

ggplot(fitted, aes(x=yhat, y=y))+
  geom_jitter()+
  geom_line(aes(x=y, y=y))

mse
```

After that we will do some feature engineering to see if there is an improvement

These are unused codes

```{r}
library(sqldf)
sqldf("Select * from data_f where MasVnrType is null")

c<-sqldf("Select MSZoning, MSSubClass, count(*) from missing
group by MSZoning,MSSubClass
      ")

FV<-sqldf("Select MSZoning, Street, count(*) total, sum(case when LotFrontage is null then 1 else 0 end) count_missing
          from data_f
          group by 1,2")

FV<-sqldf("Select *, sum(count_missing)/sum(total) from FV")
#create_report(data)


VIOLIN PLOT
vp1 <- ggplot(mcd, aes(x=MSSubClass, y=SalePrice)) +
  geom_violin()+
  geom_boxplot(width=0.1)
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
