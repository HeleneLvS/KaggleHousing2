---
title: "R Notebook for the Housepricing Comp"
output: html_notebook
---

```{r setup, include=FALSE}
options(scipen=999) ###No scientific notifications
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message =  FALSE)
```

```{r admin, include = FALSE}
##clean out the space
rm(list=ls())
options(scipen=999)

##What do we need
library(tidyr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(cowplot) # plot different ggplots next to each other
library(DataExplorer) # Best EDA package by far
library(corrplot)
library(pscl) # For Pseudo R squareds on GLMS

#Where will we work
#getwd()
setwd("C:/Users/helen/Documents/Kaggle/HousePrice/KaggleHousing")

```

The Data explorer package is great for a first stab at unknown data. First things first;

-   The dependent variable - the thing we want to predict - is continuous --\> regression problem
    -   GLM: Gamma with Log, Inverse or Identity link
    -   Regression Tree
    -   Random Forrest Reg Tree
-   Not normally distributed --\> important to match the algo to the distribution transformation
    -   Gool ol' OLS with a transformation?
-   Loads of missing data to remedy
    -   Which means we should add the test and train sets together - to save effort when scoring & validating

```{r EDA}

train<-read.csv("train.csv")

train['Type']<-'train_set'

test<-read.csv("test.csv")
test['SalePrice'] <- NA
test['Type']<-'test_set'

data<-rbind(train,test)

#create_report(train)
#create_report(data)
plot_intro(data)
plot_missing(data)
```

Start by filling in the missing data and running some correlation plots to understand the multicollinearity;

-   By completing the NA values we drop from 5.8% missing observations to 0.33%

-   The remaining two significantly missing values are for

    -   LotFrontage and

    -   Garage built

-   The latter's missing value shows there is no Garage on the premises while the LotFrontage might just show that the property is not on a municipal street. However this may be an incorrect assumption so an alternative is to build a model on LotFrontage as a factor of LotConfig and LotArea. On closer inspection imputing missings with 0's ruins a pretty nice linear correlation between SalePrice and LotFrontage so lets start with the model. There is a separate Impute notebook for details on this. Garage built will be imputed with 3000 to represent the future.

```{r CleanupandFilled}
    #Fill in the NA's where they represent 'None Present' with 'Non' 

data_f<-data %>%
      replace_na(list(Alley = "Non", BsmtQual = "Non", BsmtExposure = "Non",
                      BsmtCond= "Non", BsmtFinType1="Non", BsmtFinType2="Non",
                      FireplaceQu = "Non", GarageType = "Non",GarageFinish = "Non",
                      GarageQual="Non", GarageCond="Non", 
                      PoolQC="Non", Fence = "None", GarageQual="Non", 
                      GarageCond = "Non", PoolQC = "Non", MiscFeature = "Non"))

data_f<-data_f %>% 
      replace_na(list(GarageYrBlt = 3000))
    ## Add this bit for another set: LotFrontage = 0, if the above gives a poor result

##IMPUTE LOTFRONTAGE
## Predict the LotFrontage based on total sqft and Configuration of the lot with m.lf
data_ltz<-subset(data_f, is.na(LotFrontage)==FALSE)
m.lf <- glm(LotFrontage~LotArea+LotConfig, Gamma(link="log"), data = data_ltz)    
remove(data_ltz)
newdata<-data_f
newdata$LotFrontageHat<- predict(m.lf,newdata,type="response")  
iqr<-IQR(newdata$LotFrontage,na.rm=TRUE)
q3<-quantile(newdata$LotFrontage, probs=c(0.75), na.rm=TRUE)

#Cap it
newdata$LotFrontageHat<-case_when(
newdata$LotFrontageHat >= (q3+3*iqr) ~ (q3+3*iqr),                            
      TRUE ~newdata$LotFrontageHat
      )
remove(iqr)
remove(q3)
#Impute it
newdata$LotFrontageF<-case_when(
      is.na(newdata$LotFrontage)==TRUE ~ round(newdata$LotFrontageHat,0),
                      TRUE ~newdata$LotFrontage)
newdata$Cat<-case_when(
      is.na(newdata$LotFrontage)==TRUE ~ "Impute",
                      TRUE ~ "Original")

#Add it back to the dataset we are cleaning
data_f$LotFrontage<-newdata$LotFrontageF
data_f$LotFCat<-newdata$Cat
remove(newdata)
#create_report(data_f)
plot_intro(data_f)
plot_missing(data_f)
```

USE BELOW SECTION FOR GRAPHS AND EXPLORATION

```{r Rondtossery}
xx=data_f$Exterior1st
yy=data_f$SalePrice
x2 = data_f$Exterior2nd


summary(xx)
####DELETE HERE
a<-ggplot(data=data_f, aes(x=xx, y=yy))+
  geom_boxplot()
ggplot(data = data_fg, aes(x=Exterior1st, y = SalePrice))+geom_boxplot()


b<-ggplot(data=data_fg, aes(x=Exterior1st))+
  geom_bar()+
  geom_text(aes(label = ..count..), stat = "count")


plot_grid(a,b,ncol = 1,nrow=2)
#ggplot(data = data_f, aes(x=xx, y= yy))+
 # geom_point(aes(x=xx, y= yy), col= "blue")+
#  geom_point(aes(x=x2, y= yy), col="red", shape =0)+
#  geom_smooth()
  
ggplot(data=data_f, aes(x=Exterior1st, fill = Exterior2nd, y = 1 ) )+
  geom_bar(position="fill", stat="identity") 
  

#ggplot(data=data_fg, aes(x=xx, y=LotFrontageF))+
#  geom_boxplot()

```

```{r}
a<-ggplot(data_f, aes(x=Condition2, y=SalePrice))+
  geom_boxplot()

b<-ggplot(data_f, aes(x=Condition2))+
  geom_bar()+
  geom_text(aes(label = ..count..), stat = "count")

plot_grid(a, b, ncol = 2, nrow = 1)

ggplot(data=data_f, aes(x=Condition2, fill = HouseStyle, y = 1 ) )+
  geom_bar(position="fill", stat="identity") 
#levels(as.factor(data_fg$HouseStyle))
subset(data_f, Condition1 != "Norm")


```

```{r REGROUPING}
##Regroup poorly represented factor levels
#Data_fg will be the set that is used for modelling

#plot_missing(data_f[,1:12])

#data_fg<-data_f
data_fg<-data_f[,81:82]

#Resulting factor changes
data_fg$Era<-as.factor(case_when(data_f$MSSubClass == 20 ~ 'Newer',
                   data_f$MSSubClass == 60 ~ 'Newer',
                   data_f$MSSubClass == 120 ~ 'Newer',  
                   data_f$MSSubClass == 160 ~ 'Newer',
                     data_f$MSSubClass == 30 ~ 'Older',
                     data_f$MSSubClass == 70 ~ 'Older',
                   TRUE ~ 'NoAgeDifferentiation'  ))

data_fg$MSZoning<-as.factor(case_when(data_f$MSZoning ==  "C (all)"  ~ "C (all)",
                            data_f$MSZoning =="FV" ~ "FV",
                            data_f$MSZoning == "RL" ~ "RL/RP",
                            data_f$MSZoning == "RP" ~ "RL/RP",
                            TRUE ~'Other'))

data_fg$MSZoning <-fct_reorder(data_fg$MSZoning, data_fg$SalePrice)

data_fg$LotFrontageF<-data_f$LotFrontage
data_fg$LotArea<-data_f$LotArea
data_fg$Street<-as.factor(data_f$Street)
data_fg$Alley<-as.factor(data_f$Alley)

data_fg$LotShape<-as.factor(case_when(data_f$LotShape == "Reg" ~ "Reg",
                            TRUE ~ "Irreg"))

data_fg$LandContour<- as.factor(case_when(data_f$LandContour == "HLS" ~ "Other",
                                          data_f$LandContour == "Low" ~ "Other",
                                          TRUE ~ data_f$LandContour))

#Discard Utilities
data_fg$LotConfig <- as.factor(data_f$LotConfig)
data_fg$LandSlope<-as.factor(case_when(data_f$LandSlope == "Gtl" ~ "Gtl",
                            TRUE ~ "Sloped"))
data_fg$Neighborhood <- as.factor(data_f$Neighborhood)
data_fg$Condition1 <- (case_when(
                                 substring(data_f$Condition1,1,3) == "RRN" ~ "RRN",
                                 substring(data_f$Condition1,1,3) == "RRA" ~ "RRA",
                                 TRUE ~ substring(data_f$Condition1,1,3)
                                        )                                         
                                )
data_fg$Condition2 <- (case_when(
                                 data_f$Condition2 == "Norm" ~ "Nor",
                                 substring(data_f$Condition2,1,3) == "Pos" ~ "Pos",
                                 TRUE ~ "Neg"
                                        )
                                )

data_fg$ConComb<-data_fg$Condition1 %+%"_"%+% data_fg$Condition2   

k<-ncol(data_fg)
colS<-names(data_fg[,(k-2):k])
data_fg[,colS]<-lapply(data_fg[,colS],factor)
remove(k)
remove(colS)

data_fg$BldgType<-as.factor(data_f$BldgType)
data_fg$Stories<-as.factor(case_when(data_f$HouseStyle == "1Story" ~ "1.0",
                          data_f$HouseStyle == "1.5Fin" ~ "1.5", 
                          data_f$HouseStyle =="1.5Unf" ~ "1.5",
                          data_f$HouseStyle == "2Story" ~ "2.0",          
                          data_f$HouseStyle == "2.5Fin" ~ "2.5",
                          data_f$HouseStyle == "2.5Unf" ~ "2.5",  
                          TRUE ~ 'Other'  ))

data_fg$YearBuilt<-data_f$YearBuilt
data_fg$AgeOfHse<-year(now()) - data_f$YearBuilt

data_fg$YearRemodAdd<-case_when(data_f$YearRemodAdd<=data_f$YearBuilt ~ data_f$YearBuilt,
                                TRUE ~ data_f$YearRemodAdd)
data_fg$YrsSRemod<-year(now()) - data_fg$YearRemodAdd
data_fg$RemodYN<- case_when(data_fg$YearRemodAdd==data_fg$YearBuilt ~ "Y",
                            TRUE ~ "N")
data_fg$RoofStyle<- as.factor(data_f$RoofStyle)
data_fg$RoofMatl<-as.factor(case_when(data_f$RoofMatl == "CompShg" ~ "CompShg",
                                      TRUE ~ "Other"))
data_fg$Exterior1st<-case_when(data_f$Exterior1st %in% c("AsphShn","BrkComm","CBlock", "ImStucc", "Other", "PreCast", "Stone") ~ "Other",
                               is.na(data_f$Exterior1st) ~ "Other",
                               TRUE ~ data_f$Exterior1st)

unique(data_f$Exterior1st)
str(data_fg)
plot_missing(data_fg)
plot_correlation(data_fg)


####
      replace_na(list( BsmtQual = "Non", BsmtExposure = "Non",
                      BsmtCond= "Non", BsmtFinType1="Non", BsmtFinType2="Non",
                      FireplaceQu = "Non", GarageType = "Non",GarageFinish = "Non",
                      GarageQual="Non", GarageCond="Non", 
                      PoolQC="Non", Fence = "None", GarageQual="Non", 
                      GarageCond = "Non", PoolQC = "Non", MiscFeature = "Non")
######



data_fg$SaleType<-as.factor(case_when(data_f$SaleType == 'COD' ~ 'COD',
          data_f$SaleType == 'Con' ~ 'GCon', #Contract grouped
          data_f$SaleType == 'ConLw' ~ 'GCon',
          data_f$SaleType == 'ConLI' ~ 'GCon',
          data_f$SaleType == 'ConLD' ~ 'GCon',
          data_f$SaleType == 'New' ~ 'New',
          data_f$SaleType == 'WD' ~ 'GWD',
          data_f$SaleType == 'CWD' ~ 'GWD',
          data_f$SaleType == 'VWD' ~ 'GWD',
          TRUE ~'Other'
          ))
data_fg$SaleType<-(fct_reorder(data_fg$SaleType, data_fg$SalePrice))



#DROP THE FOLLOWING DATA COLUMNS FOR POOR EXPOSURE/VARIANCE
#Utilities

plot_correlation(data_fg)
```

remaining missing rows for the training data set can't be explained. Let's drop these rows from the training set to run our first few models. The new plots show we have a complete data set

```{r FillingInMissing}
subset(mcd, is.na(MSZoning) == TRUE )

#training set
data_f_t<-subset(data_f, Type=="train_set")            
data_f_t<-subset(data_f_t, is.na(MasVnrType) == FALSE )
data_f_t<-subset(data_f_t, is.na(Electrical) == FALSE )
check if these are in the training or the test set
plot_intro(data_f_t)
plot_missing(data_f_t)  
#create_report(data_f_t)


```

The correlation heatmap from the ExploratoryData package's report is too dense to read properly. For a parameterised model multicollinearity is not good at all.

```{r MULTICOLLINEARITY}
factorNames <- c('MSSubClass', 'MSZoning')
data_f <- data_f %>%
  mutate(across(factorNames, as.factor))

str(data_f)

data_f<-
mcd<-data_f[,c(2:3,81)]
plot_correlation(mcd)
plot_correlation(mcd$MSZoning)

b1<-ggplot(data=mcd, aes(x=MSSubClass, y=SalePrice))+
  geom_boxplot()

b2<-ggplot(data=mcd, aes(x=MSZoning, y=SalePrice))+
  geom_boxplot()

g1<-ggplot(data=mcd, aes(x=MSSubClass) )+
  geom_bar() 

g2<-ggplot(data=mcd, aes(x=MSZoning) )+
  geom_bar() 

plot_grid(b1, g1, ncol = 2, nrow = 1)
plot_grid(b2, g2, ncol = 2, nrow = 1)

subset(mcd, is.na(MSZoning) == TRUE )
```

```{r DependentDistributionExploration}

ggplot(data_f_t, aes(x=SalePrice))+
  geom_density(aes(x=SalePrice, y=..density..))

data_f_t$logPrice<-log(data_f_t$SalePrice)

ggplot(data_f_t)+
  geom_density(aes(x=logPrice, y=..density..))


```

The natural log transform does seem to make the dependent variable more symmetrical. Lets explore the three GLMs (Gamma:log, Gamma:inv, gamma:id) with a forward stepwise variable selection to decide which GLM is best

In terms of the model selevction we need a good balance between Mcfadden's pseudo R-square, Nagelkerke's R-square and plain R-square. As expected the McF's R2 is severely penalised due to too many parameters.

```{r}
library(stats)
library(caTools)

str(data_f_t)
#We need to remove the variables we do not want to use in the model;
data_f_t<-data_f_t[,2:81]
set.seed(101) 
sample = sample.split(data_f_t$SalePrice, SplitRatio = .85)
T_Train = subset(data_f_t, sample == TRUE)
T_Val  = subset(data_f_t, sample == FALSE)


glm.M1<-glm(SalePrice~.,
            family=Gamma(link = "log"),
            data    = T_Train)

with(summary(glm.M1), 1 - deviance/null.deviance)
format( pR2(glm.M1), scientific = FALSE)
#summary(glm.M1)

step_gamma_glm<-step(glm.M1)
step_gamma_glm$aic
step_gamma_glm$anova
step_gamma_glm$finalModel

x<-step_gamma_glm$model
yhat<-step_gamma_glm$fitted.values
y<-T_Train$SalePrice
fitted<-as.data.frame(cbind(yhat,y))

finalModel<-glm(formula = SalePrice ~ MSZoning + LotArea + Street + LandContour + 
    Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + 
    Condition2 + BldgType + OverallQual + OverallCond + YearBuilt + 
    YearRemodAdd + RoofMatl + Exterior1st + MasVnrArea + ExterCond + 
    Foundation + BsmtExposure + BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF + 
    Heating + HeatingQC + CentralAir + X1stFlrSF + X2ndFlrSF + 
    LowQualFinSF + BsmtFullBath + FullBath + HalfBath + KitchenAbvGr + 
    KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + GarageYrBlt + 
    GarageCars + GarageArea + GarageQual + GarageCond + WoodDeckSF + 
    EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + PoolQC + 
    Fence + SaleType + SaleCondition, family = Gamma(link = "log"), 
    data = T_Train)
summary(finalModel)



valResult<-predict(finalModel,T_Val)

ggplot(fitted, aes(x=yhat, y=y))+
  geom_jitter()+
  geom_line(aes(x=y, y=y))

mse
```

After that we will do some feature engineering to see if there is an improvement

These are unused codes

```{r}
library(sqldf)
sqldf("Select * from data_f where MasVnrType is null")

c<-sqldf("Select MSZoning, MSSubClass, count(*) from missing
group by MSZoning,MSSubClass
      ")

FV<-sqldf("Select MSZoning, Street, count(*) total, sum(case when LotFrontage is null then 1 else 0 end) count_missing
          from data_f
          group by 1,2")

FV<-sqldf("Select *, sum(count_missing)/sum(total) from FV")
#create_report(data)


VIOLIN PLOT
vp1 <- ggplot(mcd, aes(x=MSSubClass, y=SalePrice)) +
  geom_violin()+
  geom_boxplot(width=0.1)
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
